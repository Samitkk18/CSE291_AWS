{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee63f4f8",
   "metadata": {},
   "source": [
    "## 2.1 Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6b4621",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3, cv2, time, numpy as np, matplotlib.pyplot as plt, random, os, concurrent.futures\n",
    "from sagemaker.pytorch import PyTorchPredictor\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158dcccc-905b-4448-8570-94015bc67d19",
   "metadata": {},
   "source": [
    "## 2.2 Check if Endpoint creation is successful and create the predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74487be9-e5dd-4a4c-aed6-75a2e895aace",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Name: yolov8-pytorch-2024-03-11-22-32-49-022341\n",
      "Endpoint Status = InService\n"
     ]
    }
   ],
   "source": [
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "\n",
    "# Restore the endpoint name stored in the 1_DeployEndpoint.ipynb notebook\n",
    "%store -r ENDPOINT_NAME\n",
    "print(f'Endpoint Name: {ENDPOINT_NAME}')\n",
    "\n",
    "endpoint_created = False\n",
    "while True:\n",
    "    response = sm_client.list_endpoints()\n",
    "    for ep in response['Endpoints']:\n",
    "        print(f\"Endpoint Status = {ep['EndpointStatus']}\")\n",
    "        if ep['EndpointName']==ENDPOINT_NAME and ep['EndpointStatus']=='InService':\n",
    "            endpoint_created = True\n",
    "            break\n",
    "    if endpoint_created:\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c86427f-5528-4bdd-b214-15a777ee56da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = PyTorchPredictor(endpoint_name=ENDPOINT_NAME,\n",
    "                             deserializer=JSONDeserializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8dfe898-267f-422c-bc26-65ac691489fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "import boto3\n",
    "import time\n",
    "import random\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "952ea99b-bed8-4e7c-a9b6-c7502d9e0f90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to record CPU and memory usage over time\n",
    "def record_usage(usage_stats):\n",
    "    while keep_recording:\n",
    "        cpu_percent = psutil.cpu_percent()\n",
    "        memory_info = psutil.virtual_memory()\n",
    "        usage_stats.append((time.time(), cpu_percent, memory_info.percent))\n",
    "        time.sleep(1) \n",
    "\n",
    "# Function to start the monitoring thread\n",
    "def start_monitoring():\n",
    "    global keep_recording\n",
    "    keep_recording = True\n",
    "    usage_stats = []\n",
    "    monitor_thread = threading.Thread(target=record_usage, args=(usage_stats,))\n",
    "    monitor_thread.start()\n",
    "    return usage_stats, monitor_thread\n",
    "\n",
    "# Function to stop the monitoring thread\n",
    "def stop_monitoring(monitor_thread):\n",
    "    global keep_recording\n",
    "    keep_recording = False\n",
    "    monitor_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e80153-2b64-4b6f-9209-8809e9ac6145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_image(payload):\n",
    "    result = predictor.predict(payload)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cf321f3-7975-4d60-b7b4-6671ad4c21a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ec72a4",
   "metadata": {},
   "source": [
    "## 2.3 Run Inference and Generate output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0180fcb-ea19-4fc5-80a9-fdaad7f8e8b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:09<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples: 1, mean time = 0.9166964530944824, std dev = 0.021951412835872125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:35<00:00, 31.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples: 5, mean time = 29.650296640396117, std dev = 7.971872817991643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [08:33<00:00, 102.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples: 25, mean time = 99.85183701515197, std dev = 0.5289954477289633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [16:55<00:00, 203.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples: 50, mean time = 199.24915890693666, std dev = 0.5348669950717675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup S3 client and variables\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'jmayank'\n",
    "prefix = 'data/'\n",
    "response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "global_image_paths = [x['Key'] for x in response['Contents']][1:]\n",
    "num_iters = 5\n",
    "\n",
    "\n",
    "# Main profiling loop\n",
    "for num_samples in [1, 5, 25, 50]:\n",
    "    times = []\n",
    "    all_cpu_usages = []\n",
    "    all_memory_usages = []\n",
    "\n",
    "    for _ in tqdm(range(num_iters)):\n",
    "        # Start monitoring\n",
    "        usage_stats, monitor_thread = start_monitoring()\n",
    "\n",
    "        image_paths = random.sample(global_image_paths, num_samples)\n",
    "        payload_list = []\n",
    "        # Your image processing logic here\n",
    "        for file_name in image_paths:\n",
    "            # Download the image from S3\n",
    "            file_obj = s3_client.get_object(Bucket=bucket_name, Key=file_name)\n",
    "            file_content = file_obj['Body'].read()\n",
    "\n",
    "            # Convert bytes to numpy array\n",
    "            nparr = np.frombuffer(file_content, np.uint8)\n",
    "            orig_image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "\n",
    "            image_height, image_width, _ = orig_image.shape\n",
    "            model_height, model_width = 300, 300\n",
    "            x_ratio = image_width/model_width\n",
    "            y_ratio = image_height/model_height\n",
    "\n",
    "            resized_image = cv2.resize(orig_image, (model_height, model_width))\n",
    "            payload = cv2.imencode('.jpg', resized_image)[1].tobytes()\n",
    "            payload_list.append(payload)\n",
    "\n",
    "        total_infer_time_start = time.time()\n",
    "\n",
    "        with Pool(processes=10) as pool:\n",
    "            results = pool.map(process_image, payload_list)\n",
    "\n",
    "\n",
    "        total_infer_time_end = time.time()\n",
    "        times.append(total_infer_time_end - total_infer_time_start)\n",
    "\n",
    "        for result in results:\n",
    "            if 'boxes' in result:\n",
    "                for idx,(x1,y1,x2,y2,conf,lbl) in enumerate(result['boxes']):\n",
    "                    # Draw Bounding Boxes\n",
    "                    x1, x2 = int(x_ratio*x1), int(x_ratio*x2)\n",
    "                    y1, y2 = int(y_ratio*y1), int(y_ratio*y2)\n",
    "                    color = (random.randint(10,255), random.randint(10,255), random.randint(10,255))\n",
    "                    cv2.rectangle(orig_image, (x1,y1), (x2,y2), color, 4)\n",
    "                    cv2.putText(orig_image, f\"Class: {int(lbl)}\", (x1,y1-40), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "                    cv2.putText(orig_image, f\"Conf: {int(conf*100)}\", (x1,y1-10), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "                    if 'masks' in result:\n",
    "                        # Draw Masks\n",
    "                        mask = cv2.resize(np.asarray(result['masks'][idx]), dsize=(image_width, image_height), interpolation=cv2.INTER_CUBIC)\n",
    "                        for c in range(3):\n",
    "                            orig_image[:,:,c] = np.where(mask>0.5, orig_image[:,:,c]*(0.5)+0.5*color[c], orig_image[:,:,c])\n",
    "\n",
    "            if 'probs' in result:\n",
    "                # Find Class\n",
    "                lbl = result['probs'].index(max(result['probs']))\n",
    "                color = (random.randint(10,255), random.randint(10,255), random.randint(10,255))\n",
    "                cv2.putText(orig_image, f\"Class: {int(lbl)}\", (20,20), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "\n",
    "            if 'keypoints' in result:\n",
    "                # Define the colors for the keypoints and lines\n",
    "                keypoint_color = (random.randint(10,255), random.randint(10,255), random.randint(10,255))\n",
    "                line_color = (random.randint(10,255), random.randint(10,255), random.randint(10,255))\n",
    "\n",
    "                # Define the keypoints and the lines to draw\n",
    "                # keypoints = keypoints_array[:, :, :2]  # Ignore the visibility values\n",
    "                lines = [\n",
    "                    (0, 1), (0, 2), (1, 3), (2, 4),  # Head\n",
    "                    (5, 6), (5, 7), (7, 9), (6, 8), (8, 10),  # Torso\n",
    "                    (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)  # Legs\n",
    "                ]\n",
    "\n",
    "                # Draw the keypoints and the lines on the image\n",
    "                for keypoints_instance in result['keypoints']:\n",
    "                    # Draw the keypoints\n",
    "                    for keypoint in keypoints_instance:\n",
    "                        if keypoint[2] == 0:  # If the keypoint is not visible, skip it\n",
    "                            continue\n",
    "                        cv2.circle(orig_image, (int(x_ratio*keypoint[:2][0]),int(y_ratio*keypoint[:2][1])), radius=5, color=keypoint_color, thickness=-1)\n",
    "\n",
    "                    # Draw the lines\n",
    "                    for line in lines:\n",
    "                        start_keypoint = keypoints_instance[line[0]]\n",
    "                        end_keypoint = keypoints_instance[line[1]]\n",
    "                        if start_keypoint[2] == 0 or end_keypoint[2] == 0:  # If any of the keypoints is not visible, skip the line\n",
    "                            continue\n",
    "                        cv2.line(orig_image, (int(x_ratio*start_keypoint[:2][0]),int(y_ratio*start_keypoint[:2][1])),(int(x_ratio*end_keypoint[:2][0]),int(y_ratio*end_keypoint[:2][1])), color=line_color, thickness=2)\n",
    "\n",
    "\n",
    "        #Stop monitoring\n",
    "        stop_monitoring(monitor_thread)\n",
    "\n",
    "        # Extract CPU and memory usage over time\n",
    "        timestamps = [record[0] for record in usage_stats]\n",
    "        cpu_usages = [record[1] for record in usage_stats]\n",
    "        memory_usages = [record[2] for record in usage_stats]\n",
    "        all_cpu_usages.append(cpu_usages)\n",
    "        all_memory_usages.append(memory_usages)\n",
    "\n",
    "    # Output the profiling results for this batch size\n",
    "    print(f'Num samples: {num_samples}, mean time = {np.mean(times)}, std dev = {np.std(times)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc32d95-cde6-4aa3-bb5e-00cc70d4c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_samples_in_exp = [1, 5, 25, 50]\n",
    "\n",
    "# Function to plot CPU and Memory usage\n",
    "def plot_usages(cpu_usages, memory_usages, num_samples):\n",
    "    # Assuming each entry in cpu_usages and memory_usages corresponds to a different trial\n",
    "    fig, axs = plt.subplots(2, len(num_samples_in_exp), figsize=(15, 10))\n",
    "    for i in range(len(num_samples_in_exp)):\n",
    "        # CPU Usage plots\n",
    "        axs[0, i].plot(cpu_usages[i])\n",
    "        axs[0, i].set_title(f'CPU Usage for {num_samples[i]} images')\n",
    "        axs[0, i].set_xlabel('Time (s)')\n",
    "        axs[0, i].set_ylabel('CPU Usage (%)')\n",
    "\n",
    "        # Memory Usage plots\n",
    "        axs[1, i].plot(memory_usages[i])\n",
    "        axs[1, i].set_title(f'Memory Usage for {num_samples[i]} images')\n",
    "        axs[1, i].set_xlabel('Time (s)')\n",
    "        axs[1, i].set_ylabel('Memory Usage (%)')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the plotting function with your data\n",
    "plot_usages(all_cpu_usages, all_memory_usages, num_samples_in_exp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f167efa-02b2-434c-ae35-8109154b6df8",
   "metadata": {},
   "source": [
    "## 2.4 Cleanup by removing Endpoint, Endpoint Config and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b6f40-8a02-47ff-b576-806705aeb20f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = sm_client.describe_endpoint_config(EndpointConfigName=ENDPOINT_NAME)\n",
    "print(response)\n",
    "endpoint_config_name = response['EndpointConfigName']\n",
    "\n",
    "# Delete Endpoint\n",
    "sm_client.delete_endpoint(EndpointName=ENDPOINT_NAME)\n",
    "\n",
    "# Delete Endpoint Configuration\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "\n",
    "# Delete Model\n",
    "for prod_var in response['ProductionVariants']:\n",
    "    model_name = prod_var['ModelName']\n",
    "    sm_client.delete_model(ModelName=model_name)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990223bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88567d9a-243a-4ace-8789-102cc94ba00e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67896c5-6092-46d1-a808-a1dadf8a33f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
